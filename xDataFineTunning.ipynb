{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el modelo que vamos usar con la cantidad apropiada de num_labels(5 en nuestro caso)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "id2label = {\n",
    "    0: \"muy negativo\",\n",
    "    1: \"negativo\",\n",
    "    2: \"neutral\",\n",
    "    3: \"positivo\",\n",
    "    4: \"muy positivo\"\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    \"muy negativo\": 0,\n",
    "    \"negativo\": 1,\n",
    "    \"neutral\": 2,\n",
    "    \"positivo\": 3,\n",
    "    \"muy positivo\": 4\n",
    "}\n",
    "\n",
    "\n",
    "# Load the pre-trained model with the mappings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"dccuchile/bert-base-spanish-wwm-cased\", \n",
    "    num_labels=5,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos nuestros datos procesados\n",
    "df = pd.read_excel(\"analsisDeSentimientoRedes_1_enero.xlsx\")\n",
    "\n",
    "train_text = df[\"text\"].tolist()\n",
    "train_label  = df[\"sentiment\"].map(label2id).tolist()\n",
    "\n",
    "max_len = len(max(train_text, key=len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una clase para nuestros datos donde los tokenizamos para el modelo BETO\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "class DataSetX(Dataset):\n",
    "\n",
    "    def __init__(self,text,labels,tokenizer,max_length = max_len):\n",
    "        self.texts = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            # Tokenize the input text\n",
    "            encoding = self.tokenizer(\n",
    "                self.texts[idx],\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            # Return a dictionary\n",
    "            item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return item\n",
    "\n",
    "\"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "        return {key: val.squeeze() for key, val in encoding.items()}, label\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "#We transform our data in to a type suited for the Pytorch data pipeline\n",
    "train_dataset = DataSetX(train_text, train_label, tokenizer)\n",
    "#We use HF collator to padd the data to make sure it has the same input lenght\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#We define Pytorch's Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, collate_fn=data_collator) # Output Class: <class 'torch.utils.data.dataloader.DataLoader'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8718,  0.6004, -1.3210,  2.5397, -1.8669],\n",
      "        [-0.9049,  2.2967, -0.2428,  0.9813, -2.3972],\n",
      "        [-0.7432,  0.0624, -0.9997,  2.5365, -1.4038],\n",
      "        [-0.9699,  2.4953, -0.2270,  0.9113, -2.2876],\n",
      "        [-0.7338,  0.1112, -0.8837,  2.6707, -1.5164],\n",
      "        [-0.8219,  0.4070, -1.2007,  2.5788, -1.5895],\n",
      "        [-1.0213,  2.6552, -0.2519,  0.6637, -2.3806],\n",
      "        [-0.8472,  0.1938, -0.9464,  2.6010, -1.6008],\n",
      "        [-0.7973,  2.5231, -0.5154,  0.1415, -2.0371],\n",
      "        [-0.7337,  0.2403, -1.0289,  2.6004, -1.5602]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.0701,  2.5495, -0.0358,  0.4475, -2.1845],\n",
      "        [-0.9241,  2.5113, -0.1966,  0.5158, -2.3121],\n",
      "        [-1.0359,  2.5425, -0.8138,  0.8246, -2.0271],\n",
      "        [-0.2814, -0.0095,  1.7380,  0.1077, -0.9427],\n",
      "        [-0.5518, -0.0756,  1.8198,  0.3252, -1.4322],\n",
      "        [-0.8778,  0.3060,  0.7469,  1.3851, -1.6909],\n",
      "        [-0.5095,  0.2679,  1.7367,  0.5594, -1.7005],\n",
      "        [-0.8461,  2.8098, -0.3526,  0.3889, -2.2652],\n",
      "        [-0.7631,  0.4321,  0.5140,  1.3419, -1.6767],\n",
      "        [-0.4275,  2.4707, -0.4591,  0.1238, -2.0210]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.7233,  1.8152,  0.8499,  0.3940, -2.3020],\n",
      "        [-0.8140,  2.3915, -0.0962,  0.8121, -2.2977],\n",
      "        [-0.7492,  2.4424, -0.2682,  0.1790, -2.0341],\n",
      "        [-0.8597,  1.6921,  0.6409,  0.7868, -2.0029],\n",
      "        [-0.6585,  2.7586, -0.3228,  0.1409, -2.2228],\n",
      "        [-0.8699,  2.6744, -0.7064,  0.5559, -2.1010],\n",
      "        [-0.8569,  0.3023, -0.8322,  2.6412, -1.7527],\n",
      "        [-0.7753,  2.5690, -0.2263, -0.0302, -2.1040],\n",
      "        [-0.8620,  0.5360, -1.0530,  2.6278, -1.8268],\n",
      "        [-1.0329,  2.3307, -0.7372,  0.9480, -2.1036]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6769,  2.6660, -0.5632,  0.1562, -2.1293],\n",
      "        [-0.6264,  0.0487, -0.8598,  2.5781, -1.2659],\n",
      "        [-0.7920,  2.0698, -0.0352,  0.5744, -2.1247],\n",
      "        [-0.9263,  2.7490, -0.5187,  0.5402, -2.3903],\n",
      "        [-1.0135,  2.6699, -0.7373,  0.6165, -2.0915],\n",
      "        [-0.7575,  2.8063, -0.4885,  0.5192, -2.3148],\n",
      "        [-1.0532,  1.6412,  0.0844,  1.3729, -2.1610],\n",
      "        [-0.4150,  2.2260, -0.1193,  0.2477, -2.0914],\n",
      "        [-0.7739,  2.7382, -0.3967,  0.3047, -2.2603],\n",
      "        [-0.7136,  2.6281, -0.4400,  0.3782, -2.1746]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6558,  2.6482, -0.5631,  0.2617, -2.2066],\n",
      "        [-0.7663,  2.3848, -0.0574,  0.0659, -2.0335],\n",
      "        [-0.7400,  2.8245, -0.5040,  0.1867, -2.1511],\n",
      "        [-0.4298,  0.4992,  1.1304,  0.3854, -1.2423],\n",
      "        [-1.0569,  2.5736, -0.6445,  0.8159, -2.0982],\n",
      "        [-0.8780,  2.7486, -0.5157,  0.6887, -2.2120],\n",
      "        [-0.7526,  0.4397, -1.0649,  2.5667, -1.6911],\n",
      "        [-0.6257,  0.0479,  1.3193,  0.4524, -1.0604],\n",
      "        [-0.8246,  1.4525,  0.0672,  1.3809, -2.1010],\n",
      "        [-0.8613,  2.7294, -0.5227,  0.4160, -2.3657]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.8954,  2.7229, -0.5358,  0.4938, -2.1916],\n",
      "        [-0.1380,  1.8221, -0.1216,  0.3339, -1.8259],\n",
      "        [-0.9707,  2.5112, -0.7392,  1.1552, -2.1352],\n",
      "        [-0.8590,  0.4808, -1.0735,  2.5245, -1.8552],\n",
      "        [-1.1244,  2.1511, -0.5645,  1.3165, -2.1600],\n",
      "        [-0.6298,  2.3508, -0.3780,  0.3679, -1.8781],\n",
      "        [-1.0226,  2.5978, -0.7076,  0.7789, -2.1896],\n",
      "        [-0.7774,  0.0697,  0.7234,  1.0486, -1.2004],\n",
      "        [-0.6866,  0.1590, -0.9732,  2.6209, -1.5117],\n",
      "        [-0.8917,  2.5633, -0.6313,  0.9305, -2.1988]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.7427,  2.5988, -0.0620,  0.3931, -2.4043],\n",
      "        [-1.0063,  2.6958, -0.7795,  0.7544, -2.1055],\n",
      "        [-0.3311, -0.3448,  1.1842,  0.5289, -0.7598],\n",
      "        [-0.9254,  2.4899, -0.5567,  0.4888, -1.9864],\n",
      "        [-0.8480,  0.6218,  0.1927,  1.4219, -1.6866],\n",
      "        [-0.6075,  0.3280,  1.6903,  0.2215, -1.6241],\n",
      "        [-0.7667,  2.4634, -0.2803,  0.2654, -2.2327],\n",
      "        [-0.8704,  0.8882,  0.6684,  0.8445, -1.8746],\n",
      "        [-0.8889,  0.9039, -0.9873,  2.3796, -2.1129],\n",
      "        [-1.0305,  2.4511, -0.6653,  0.8545, -2.0982]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.8225,  0.5204, -1.1557,  2.6349, -1.7578],\n",
      "        [-0.6102,  1.4773,  0.2329,  0.9796, -2.1864],\n",
      "        [-0.7751,  0.4259, -0.8759,  2.4994, -1.6605],\n",
      "        [-1.0392,  2.5148, -0.7150,  1.1771, -2.2663],\n",
      "        [-0.8089,  2.7125, -0.3731,  0.2503, -2.2277],\n",
      "        [-0.7249,  2.6386, -0.3302,  0.2988, -2.1298],\n",
      "        [-0.6493,  2.5894, -0.3992,  0.1348, -2.0759],\n",
      "        [-0.9551,  2.7858, -0.6544,  0.4490, -2.1041],\n",
      "        [-1.1362,  2.1037,  0.2003,  0.6174, -2.0685],\n",
      "        [-0.7819,  1.9837, -0.5722,  1.1704, -2.0031]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9415,  1.4462, -0.1468,  1.6130, -2.2062],\n",
      "        [-0.8047,  2.4580, -0.1282,  0.3617, -2.1159],\n",
      "        [-0.5771, -0.0178, -0.9337,  2.4429, -1.2681],\n",
      "        [-0.9738,  2.7374, -0.4232,  0.5227, -2.2554],\n",
      "        [-0.4838,  0.1966, -1.0376,  2.1552, -1.4685],\n",
      "        [-0.6883, -0.0104, -0.9574,  2.5363, -1.2807],\n",
      "        [-1.0938,  2.1175, -0.6878,  1.3898, -2.4434],\n",
      "        [-0.8997,  1.0762,  0.2780,  1.4012, -2.1322],\n",
      "        [-0.9836,  2.5777, -0.3954,  0.6800, -2.2886],\n",
      "        [-0.9792,  1.2131, -1.0668,  2.4093, -2.0356]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-9.2515e-01,  2.5634e+00, -5.3032e-01,  7.4905e-01, -2.1088e+00],\n",
      "        [-9.7699e-01,  2.5740e+00, -6.8654e-01,  8.4370e-01, -2.1246e+00],\n",
      "        [-5.8963e-01, -2.0140e-01,  1.3243e+00,  6.5368e-01, -1.1285e+00],\n",
      "        [-7.1662e-01,  2.6582e+00, -5.0549e-01, -2.7575e-03, -2.0769e+00],\n",
      "        [-8.5233e-01,  2.6895e+00, -6.1380e-01,  7.8708e-01, -2.2978e+00],\n",
      "        [-7.5487e-01,  2.8383e+00, -4.6048e-01,  3.3042e-01, -2.2691e+00],\n",
      "        [-9.4685e-01,  2.5060e+00, -9.0928e-03,  3.9089e-01, -2.1836e+00],\n",
      "        [-5.9307e-01,  1.4108e-01, -8.8668e-01,  2.5262e+00, -1.3850e+00],\n",
      "        [-7.4750e-01,  2.7018e+00, -2.6565e-01,  3.0987e-01, -2.1889e+00],\n",
      "        [-8.4077e-01,  2.5832e-01, -8.0169e-01,  2.5778e+00, -1.7057e+00]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 completed.\n",
      "Epoch 2/3 completed.\n",
      "Epoch 3/3 completed.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "# Define optimizer, loss function, and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # for every key(k) and value(v) in the dictionary, we transfer them to the apropriate device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        #Saves the labels of our current batch\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./trained_model\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "output_dir = \"./trained_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "output_dir = \"./trained_model\"\n",
    "\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "print(\"Model and tokenizer successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model_dir, text):\n",
    "    \"\"\"\n",
    "    Load a trained model and tokenizer from a directory and predict sentiment for a given text.\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): Directory where the trained model and tokenizer are saved.\n",
    "        text (str): The input text to analyze.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the sentiment category and associated probabilities.\n",
    "    \"\"\"\n",
    "    # Load the model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #change the output to a probability distribution\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    id2label = {0: 'muy negativo', 1: 'negativo', 2: 'neutral', 3: 'positivo', 4: 'muy positivo'}\n",
    "    sentiment = id2label[predicted_class]\n",
    "    \n",
    "    # Return the result as a dictionary\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"probabilities\": probabilities.squeeze().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'negativo', 'probabilities': [0.08135326951742172, 0.37779924273490906, 0.22624237835407257, 0.2728400230407715, 0.04176516458392143]}\n"
     ]
    }
   ],
   "source": [
    "model_directory = \"./trained_model\"\n",
    "sample_text = \"Las pymes son malas\"\n",
    "result = predict_sentiment(model_directory, sample_text)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
